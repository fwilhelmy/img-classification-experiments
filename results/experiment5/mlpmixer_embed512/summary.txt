MLPMIXER CONFIGURATION
----------------------------------------------------------------
num_classes:	10
img_size:	32
patch_size:	4
embed_dim:	512
num_blocks:	4
drop_rate:	0.0
activation:	gelu
mlp_ratio:	[0.5, 4.0]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 512, 8, 8]          25,088
        PatchEmbed-2              [-1, 64, 512]               0
         LayerNorm-3              [-1, 64, 512]           1,024
            Linear-4             [-1, 512, 256]          16,640
              GELU-5             [-1, 512, 256]               0
           Dropout-6             [-1, 512, 256]               0
            Linear-7              [-1, 512, 64]          16,448
           Dropout-8              [-1, 512, 64]               0
               Mlp-9              [-1, 512, 64]               0
        LayerNorm-10              [-1, 64, 512]           1,024
           Linear-11             [-1, 64, 2048]       1,050,624
             GELU-12             [-1, 64, 2048]               0
          Dropout-13             [-1, 64, 2048]               0
           Linear-14              [-1, 64, 512]       1,049,088
          Dropout-15              [-1, 64, 512]               0
              Mlp-16              [-1, 64, 512]               0
       MixerBlock-17              [-1, 64, 512]               0
        LayerNorm-18              [-1, 64, 512]           1,024
           Linear-19             [-1, 512, 256]          16,640
             GELU-20             [-1, 512, 256]               0
          Dropout-21             [-1, 512, 256]               0
           Linear-22              [-1, 512, 64]          16,448
          Dropout-23              [-1, 512, 64]               0
              Mlp-24              [-1, 512, 64]               0
        LayerNorm-25              [-1, 64, 512]           1,024
           Linear-26             [-1, 64, 2048]       1,050,624
             GELU-27             [-1, 64, 2048]               0
          Dropout-28             [-1, 64, 2048]               0
           Linear-29              [-1, 64, 512]       1,049,088
          Dropout-30              [-1, 64, 512]               0
              Mlp-31              [-1, 64, 512]               0
       MixerBlock-32              [-1, 64, 512]               0
        LayerNorm-33              [-1, 64, 512]           1,024
           Linear-34             [-1, 512, 256]          16,640
             GELU-35             [-1, 512, 256]               0
          Dropout-36             [-1, 512, 256]               0
           Linear-37              [-1, 512, 64]          16,448
          Dropout-38              [-1, 512, 64]               0
              Mlp-39              [-1, 512, 64]               0
        LayerNorm-40              [-1, 64, 512]           1,024
           Linear-41             [-1, 64, 2048]       1,050,624
             GELU-42             [-1, 64, 2048]               0
          Dropout-43             [-1, 64, 2048]               0
           Linear-44              [-1, 64, 512]       1,049,088
          Dropout-45              [-1, 64, 512]               0
              Mlp-46              [-1, 64, 512]               0
       MixerBlock-47              [-1, 64, 512]               0
        LayerNorm-48              [-1, 64, 512]           1,024
           Linear-49             [-1, 512, 256]          16,640
             GELU-50             [-1, 512, 256]               0
          Dropout-51             [-1, 512, 256]               0
           Linear-52              [-1, 512, 64]          16,448
          Dropout-53              [-1, 512, 64]               0
              Mlp-54              [-1, 512, 64]               0
        LayerNorm-55              [-1, 64, 512]           1,024
           Linear-56             [-1, 64, 2048]       1,050,624
             GELU-57             [-1, 64, 2048]               0
          Dropout-58             [-1, 64, 2048]               0
           Linear-59              [-1, 64, 512]       1,049,088
          Dropout-60              [-1, 64, 512]               0
              Mlp-61              [-1, 64, 512]               0
       MixerBlock-62              [-1, 64, 512]               0
        LayerNorm-63              [-1, 64, 512]           1,024
           Linear-64                   [-1, 10]           5,130
================================================================
Total params: 8,570,634
Trainable params: 8,570,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 33.75
Params size (MB): 32.69
Estimated Total Size (MB): 66.46
----------------------------------------------------------------
