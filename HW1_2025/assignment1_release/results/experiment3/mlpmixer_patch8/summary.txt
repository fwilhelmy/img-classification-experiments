MLPMIXER CONFIGURATION
----------------------------------------------------------------
num_classes:	10
img_size:	32
patch_size:	8
embed_dim:	256
num_blocks:	4
drop_rate:	0.0
activation:	gelu
mlp_ratio:	[0.5, 4.0]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 256, 4, 4]          49,408
        PatchEmbed-2              [-1, 16, 256]               0
         LayerNorm-3              [-1, 16, 256]             512
            Linear-4             [-1, 256, 128]           2,176
              GELU-5             [-1, 256, 128]               0
           Dropout-6             [-1, 256, 128]               0
            Linear-7              [-1, 256, 16]           2,064
           Dropout-8              [-1, 256, 16]               0
               Mlp-9              [-1, 256, 16]               0
        LayerNorm-10              [-1, 16, 256]             512
           Linear-11             [-1, 16, 1024]         263,168
             GELU-12             [-1, 16, 1024]               0
          Dropout-13             [-1, 16, 1024]               0
           Linear-14              [-1, 16, 256]         262,400
          Dropout-15              [-1, 16, 256]               0
              Mlp-16              [-1, 16, 256]               0
       MixerBlock-17              [-1, 16, 256]               0
        LayerNorm-18              [-1, 16, 256]             512
           Linear-19             [-1, 256, 128]           2,176
             GELU-20             [-1, 256, 128]               0
          Dropout-21             [-1, 256, 128]               0
           Linear-22              [-1, 256, 16]           2,064
          Dropout-23              [-1, 256, 16]               0
              Mlp-24              [-1, 256, 16]               0
        LayerNorm-25              [-1, 16, 256]             512
           Linear-26             [-1, 16, 1024]         263,168
             GELU-27             [-1, 16, 1024]               0
          Dropout-28             [-1, 16, 1024]               0
           Linear-29              [-1, 16, 256]         262,400
          Dropout-30              [-1, 16, 256]               0
              Mlp-31              [-1, 16, 256]               0
       MixerBlock-32              [-1, 16, 256]               0
        LayerNorm-33              [-1, 16, 256]             512
           Linear-34             [-1, 256, 128]           2,176
             GELU-35             [-1, 256, 128]               0
          Dropout-36             [-1, 256, 128]               0
           Linear-37              [-1, 256, 16]           2,064
          Dropout-38              [-1, 256, 16]               0
              Mlp-39              [-1, 256, 16]               0
        LayerNorm-40              [-1, 16, 256]             512
           Linear-41             [-1, 16, 1024]         263,168
             GELU-42             [-1, 16, 1024]               0
          Dropout-43             [-1, 16, 1024]               0
           Linear-44              [-1, 16, 256]         262,400
          Dropout-45              [-1, 16, 256]               0
              Mlp-46              [-1, 16, 256]               0
       MixerBlock-47              [-1, 16, 256]               0
        LayerNorm-48              [-1, 16, 256]             512
           Linear-49             [-1, 256, 128]           2,176
             GELU-50             [-1, 256, 128]               0
          Dropout-51             [-1, 256, 128]               0
           Linear-52              [-1, 256, 16]           2,064
          Dropout-53              [-1, 256, 16]               0
              Mlp-54              [-1, 256, 16]               0
        LayerNorm-55              [-1, 16, 256]             512
           Linear-56             [-1, 16, 1024]         263,168
             GELU-57             [-1, 16, 1024]               0
          Dropout-58             [-1, 16, 1024]               0
           Linear-59              [-1, 16, 256]         262,400
          Dropout-60              [-1, 16, 256]               0
              Mlp-61              [-1, 16, 256]               0
       MixerBlock-62              [-1, 16, 256]               0
        LayerNorm-63              [-1, 16, 256]             512
           Linear-64                   [-1, 10]           2,570
================================================================
Total params: 2,175,818
Trainable params: 2,175,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.72
Params size (MB): 8.30
Estimated Total Size (MB): 14.03
----------------------------------------------------------------
