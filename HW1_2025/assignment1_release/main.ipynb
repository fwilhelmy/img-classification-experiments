{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwilhelmy/IFT6135-2025/blob/main/HW1_2025/assignment1_release/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTv0D26B9W2h"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qFHMMDtSwuW4",
        "outputId": "71abd7ef-71f0-4ec4-ace4-031a7511420c"
      },
      "outputs": [],
      "source": [
        "#@title Mount your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oODLwt1QzgGa"
      },
      "outputs": [],
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/gdrive/MyDrive/IFT6135/HW1_2025/assignment1_release\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "  sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dt3NTvpsy4Oc"
      },
      "source": [
        "### Running on GPU\n",
        "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Param√®tres du notebook`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "RLVSmv9HoMH5",
        "outputId": "83bf8f8a-6a7a-4304-ed55-4cc6c6bc9784"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from main import Arguments, run_experiment\n",
        "from utils import save_model, load_model, generate_plots, cross_entropy_loss\n",
        "from torchsummary import summary\n",
        "import shutil\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy1J-0OroLg"
      },
      "source": [
        "# Local Test\n",
        "Before run the experiment, here are some local test cases you can run for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLEVxwLlroLh"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "import testy\n",
        "suite = unittest.TestLoader().loadTestsFromModule(testy)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PtvL_yKp3PW"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment1 = {\n",
        "    \"mlp_relu\": Arguments(logdir=\"results/experiment1/mlp_relu\", model='mlp', model_config='model_configs/mlp/mlp_relu.json'),\n",
        "    \"mlp_sigmoid\": Arguments(logdir=\"results/experiment1/mlp_sigmoid\", model='mlp', model_config='model_configs/mlp/mlp_sigmoid.json'),\n",
        "    \"mlp_tanh\": Arguments(logdir=\"results/experiment1/mlp_tanh\", model='mlp', model_config='model_configs/mlp/mlp_tanh.json'),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyJPWO1ppcTx"
      },
      "outputs": [],
      "source": [
        "run_experiment(experiment1)\n",
        "\n",
        "legend_names = ['ReLU', 'Sigmoid', 'Tanh']\n",
        "logdirs = [experiment1[key].logdir for key in experiment1]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment1.zip results/experiment1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment2 = {\n",
        "    \"resnet18_lr1e-1\": Arguments(logdir=\"results/experiment2/resnet18_lr1e-1\", model='resnet18', model_config='model_configs/resnet18.json', optimizer='adam', epochs=10, lr=1e-1),\n",
        "    \"resnet18_lr1e-2\": Arguments(logdir=\"results/experiment2/resnet18_lr1e-2\", model='resnet18', model_config='model_configs/resnet18.json', optimizer='adam', epochs=10, lr=1e-2),\n",
        "    \"resnet18_lr1e-3\": Arguments(logdir=\"results/experiment2/resnet18_lr1e-3\", model='resnet18', model_config='model_configs/resnet18.json', optimizer='adam', epochs=10, lr=1e-3),\n",
        "    \"resnet18_lr1e-4\": Arguments(logdir=\"results/experiment2/resnet18_lr1e-4\", model='resnet18', model_config='model_configs/resnet18.json', optimizer='adam', epochs=10, lr=1e-4),\n",
        "    \"resnet18_lr1e-5\": Arguments(logdir=\"results/experiment2/resnet18_lr1e-5\", model='resnet18', model_config='model_configs/resnet18.json', optimizer='adam', epochs=10, lr=1e-5),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiment(experiment2)\n",
        "\n",
        "legend_names = ['1e-1', '1e-2', '1e-3', '1e-4', '1e-5']\n",
        "logdirs = [experiment2[x].logdir for x in experiment2]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment2.zip results/experiment2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment3 = {\n",
        "    \"mlpmixer_patch2\": Arguments(logdir=\"results/experiment3/mlpmixer_patch2\", model='mlpmixer', model_config='model_configs/mlpmixer/mlpmixer_patch2.json', epochs=15),\n",
        "    \"mlpmixer_patch4\": Arguments(logdir=\"results/experiment3/mlpmixer_patch4\", model='mlpmixer', model_config='model_configs/mlpmixer/mlpmixer_patch4.json', epochs=15),\n",
        "    \"mlpmixer_patch8\": Arguments(logdir=\"results/experiment3/mlpmixer_patch8\", model='mlpmixer', model_config='model_configs/mlpmixer/mlpmixer_patch8.json', epochs=15)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiment(experiment3)\n",
        "\n",
        "legend_names = ['Patch 2', 'Patch 4', 'Patch 8']\n",
        "logdirs = [experiment3[x].logdir for x in experiment3]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment3.zip results/experiment3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment4 = {\n",
        "    \"resnet18_SGDMomentum_baseline\": Arguments(\n",
        "        logdir=\"results/experiment4/resnet18_SGDMomentum_baseline\",\n",
        "        model='resnet18',\n",
        "        model_config='model_configs/resnet18.json',\n",
        "        optimizer='momentum',\n",
        "        lr=0.01,\n",
        "    ),\n",
        "    \"resnet18_SGDMomentum_wd1e-3\": Arguments(\n",
        "        logdir=\"results/experiment4/resnet18_SGDMomentum_wd1e-3\",\n",
        "        model='resnet18',\n",
        "        model_config='model_configs/resnet18.json',\n",
        "        optimizer='momentum',\n",
        "        lr=0.01,\n",
        "        weight_decay=1e-3, # increased weight decay\n",
        "    ),\n",
        "    \"resnet18_SGDMomentum_lr1e-1\": Arguments(\n",
        "        logdir=\"results/experiment4/resnet18_SGDMomentum_lr1e-1\",\n",
        "        model='resnet18',\n",
        "        model_config='model_configs/resnet18.json',\n",
        "        optimizer='momentum',\n",
        "        lr=0.1, # higher learning rate\n",
        "    ),\n",
        "    \"resnet18_AdamW\": Arguments(\n",
        "        logdir=\"results/experiment4/resnet18_AdamW\",\n",
        "        model='resnet18',\n",
        "        model_config='model_configs/resnet18.json',\n",
        "        optimizer='adamw',\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiment(experiment4)\n",
        "\n",
        "legend_names = [\"SGD Momentum (Baseline)\", \"SGD Momentum (WD=1e-3)\", \"SGD Momentum (LR=0.1)\", \"AdamW\"]\n",
        "logdirs = [experiment4[x].logdir for x in experiment4]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "legend_names = [\"Momentum (Baseline)\", \"Momentum (Inscreased WD)\", \"Momentum (Inscreased LR)\", \"AdamW\"]\n",
        "logdirs = [experiment4[x].logdir for x in experiment4]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for logdir in logdirs:\n",
        "    model = load_model(logdir, torch.device('cpu'))\n",
        "    model.visualize(logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment4.zip results/experiment4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment5 = {\n",
        "    \"mlpmixer_dropout\": Arguments(\n",
        "        logdir=\"results/experiment5/mlpmixer_dropout\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_dropout.json',\n",
        "    ),\n",
        "    \"mlpmixer_embed512\": Arguments(\n",
        "        logdir=\"results/experiment5/mlpmixer_embed512\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_embed512.json',\n",
        "    ),\n",
        "    \"mlpmixer_deep\": Arguments(\n",
        "        logdir=\"results/experiment5/mlpmixer_deep\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_deep.json',\n",
        "    ),\n",
        "    \"mlpmixer_combined\": Arguments(\n",
        "        logdir=\"results/experiment5/mlpmixer_combined\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_combined.json',\n",
        "    ),\n",
        "    \"mlpmixer_combined_dropout\": Arguments(\n",
        "        logdir=\"results/experiment5/mlpmixer_combined_dropout\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_combined_dropout.json',\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiment(experiment5)\n",
        "\n",
        "# Since the baseline experiment was already done in experiment 3, just copy the results to experiment 5 results\n",
        "shutil.copytree(\"results/experiment3/mlpmixer_patch4\", \"results/experiment5/mlpmixer_baseline\")\n",
        "\n",
        "legend_names = [\"Baseline\", \"Dropout\", \"Embedding 512\", \"Deep\", \"Combined\", \"Combined with Dropout\"]\n",
        "logdirs = [\"results/experiment5/mlpmixer_baseline\"] + [experiment5[x].logdir for x in experiment5]\n",
        "\n",
        "generate_plots(logdirs, legend_names, \"results/experiment5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "legend_names = [\"Baseline\", \"Dropout\", \"Embedding 512\", \"Deep\", \"Combined\", \"Combined with Dropout\"]\n",
        "logdirs = [\"results/experiment5/mlpmixer_baseline\"] + [experiment5[x].logdir for x in experiment5]\n",
        "\n",
        "for logdir in logdirs:\n",
        "    model = load_model(logdir, torch.device('cpu'))\n",
        "    model.visualize(0, logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment5.zip results/experiment5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment6 = {\n",
        "    \"mlpmixer_increased_token\": Arguments(\n",
        "        logdir=\"results/experiment6/mlpmixer_increased_token\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_increased_token.json',\n",
        "    ),\n",
        "    \"mlpmixer_increased_channel\": Arguments(\n",
        "        logdir=\"results/experiment6/mlpmixer_increased_channel\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_increased_channel.json',\n",
        "    ),\n",
        "    \"mlpmixer_balanced_ratio\": Arguments(\n",
        "        logdir=\"results/experiment6/mlpmixer_balanced_ratio\",\n",
        "        model='mlpmixer',\n",
        "        model_config='model_configs/mlpmixer/mlpmixer_balanced_ratio.json',\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiment(experiment6)\n",
        "\n",
        "# Since the baseline experiment was already done in experiment 3, just copy the results to experiment 6 results\n",
        "shutil.copytree(\"results/experiment3/mlpmixer_patch4\", \"results/experiment6/mlpmixer_baseline\")\n",
        "\n",
        "legend_names = [\"Baseline\", \"Increased Token\", \"Increased Channel\", \"Balanced Ratio\"]\n",
        "logdirs = [\"results/experiment6/mlpmixer_baseline\"] + [experiment6[x].logdir for x in experiment6]\n",
        "\n",
        "generate_plots(logdirs, legend_names, f\"results/experiment6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for logdir in logdirs:\n",
        "    model = load_model(logdir, torch.device('cpu'))\n",
        "    model.visualize(1, logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment6.zip results/experiment6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 7\n",
        "\n",
        "Compare the gradient flow (e.g., norms of gradients at different layers) during backpropagation for all three architectures (MLP, ResNet18 and MLPMixer). Analyze and compare the behavior of gradients in each architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment7 = {}\n",
        "\n",
        "run_experiment(experiment7)\n",
        "\n",
        "legend_names = []\n",
        "logdirs = []\n",
        "\n",
        "generate_plots(logdirs, legend_names, f\"results/experiment7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r experiment7.zip results/experiment7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Block for running all experiments in one go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments = [experiment1, experiment2, experiment3, experiment4, experiment5, experiment6]\n",
        "\n",
        "for experiment in experiments:\n",
        "    # update all contents in experiment to have 30 epochs\n",
        "    for key in experiment:\n",
        "        experiment[key].epochs = 30 \n",
        "    run_experiment(experiment, True, 1)\n",
        "\n",
        "shutil.copytree(\"results/experiment3/mlpmixer_patch4\", \"results/experiment5/mlpmixer_baseline\")\n",
        "shutil.copytree(\"results/experiment3/mlpmixer_patch4\", \"results/experiment6/mlpmixer_baseline\")\n",
        "\n",
        "legend_names = [[\"ReLU\", \"Sigmoid\", \"Tanh\"], [x for x in experiment2], [x for x in experiment3.keys()], [\"SGDMomentum_baseline\", \"SGDMomentum_wd1e-3\", \"SGDMomentum_lr1e-1\", \"AdamW\"], [\"Baseline\", \"Dropout\", \"Embedding 512\", \"Deep\", \"Combined\"], [\"Baseline\", \"Increased Token\", \"Increased Channel\", \"Balanced Ratio\"]]\n",
        "logdirs = [[experiment1[key].logdir for key in experiment1], [experiment2[x].logdir for x in experiment2], [experiment3[x].logdir for x in experiment3], [experiment4[x].logdir for x in experiment4], [\"results/experiment5/mlpmixer_base\"] + [experiment5[x].logdir for x in experiment5], [\"results/experiment6/mlpmixer_base\"] + [experiment6[x].logdir for x in experiment6]]\n",
        "\n",
        "for i, experiment in enumerate(experiments):\n",
        "    generate_plots(logdirs[i], legend_names[i], f\"results/experiment{i+1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# utils\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import cross_entropy_loss, load_model\n",
        "from metrics import convergence_speed, stability, gradient_norms\n",
        "\n",
        "# Set up experiment configuration and identifier\n",
        "experiment_id = \"experiment3\"\n",
        "experiment = experiment3\n",
        "\n",
        "# 1. Aggregate results from each experiment into one JSON file\n",
        "all_results = {}\n",
        "for exp_name, args in experiment.items():\n",
        "    results_file = os.path.join(args.logdir, \"results.json\")\n",
        "    with open(results_file, \"r\") as f:\n",
        "        all_results[exp_name] = json.load(f)\n",
        "\n",
        "results_save_path = os.path.join(\"results\", experiment_id, \"results.json\")\n",
        "with open(results_save_path, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=4)\n",
        "\n",
        "# 2. Define transforms and dataloaders for CIFAR-10\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_dataset = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, transform=test_transform, download=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# 3. Generate metrics.txt by writing computed metrics for each experiment\n",
        "metrics_save_path = os.path.join(\"results\", experiment_id, \"metrics.txt\")\n",
        "with open(metrics_save_path, \"w\") as metrics_file:\n",
        "    for exp_name, args in experiment.items():\n",
        "        results_file = os.path.join(args.logdir, \"results.json\")\n",
        "        with open(results_file, \"r\") as f:\n",
        "            results = json.load(f)\n",
        "        \n",
        "        # Load model (assumes load_model is defined in your utils)\n",
        "        model = load_model(args.logdir, torch.device('cpu'))\n",
        "        \n",
        "        # Compute convergence speed (epoch when validation accuracy first reaches 65%)\n",
        "        conv_epoch = convergence_speed(results[\"valid_accs\"], threshold=0.65)\n",
        "        metrics_file.write(f\"Experiment {exp_name}: Convergence epoch = {conv_epoch}\\n\")\n",
        "        \n",
        "        # Compute stability: variance of training and validation accuracy over the last 5 epochs\n",
        "        train_acc_var = stability(results[\"train_accs\"], last_n=5)\n",
        "        valid_acc_var = stability(results[\"valid_accs\"], last_n=5)\n",
        "        metrics_file.write(f\"Experiment {exp_name}: Training accuracy variance (last 5 epochs) = {train_acc_var:.4f}\\n\")\n",
        "        metrics_file.write(f\"Experiment {exp_name}: Validation accuracy variance (last 5 epochs) = {valid_acc_var:.4f}\\n\")\n",
        "        \n",
        "        # Compute gradient norms for one batch from the training dataloader\n",
        "        grad_norms_val = gradient_norms(model, train_dataloader, 'cpu')\n",
        "        metrics_file.write(f\"Experiment {exp_name}: Gradient norms (first batch) = {grad_norms_val}\\n\")\n",
        "\n",
        "# 4. Generate summary.txt by aggregating each experiment's summary file\n",
        "summary_save_path = os.path.join(\"results\", experiment_id, \"summary.txt\")\n",
        "with open(summary_save_path, \"w\") as outfile:\n",
        "    for config_key, args_obj in experiment.items():\n",
        "        outfile.write(f\"### {config_key}\\n\\n\")\n",
        "        summary_file = os.path.join(args_obj.logdir, \"summary.txt\")\n",
        "        if os.path.exists(summary_file):\n",
        "            with open(summary_file, \"r\") as infile:\n",
        "                content = infile.read()\n",
        "            outfile.write(content)\n",
        "        else:\n",
        "            outfile.write(\"Summary file not found.\\n\")\n",
        "        outfile.write(\"\\n\\n\")\n",
        "\n",
        "# 5. Generate the final aggregated file that combines all the outputs\n",
        "final_save_path = os.path.join(\"results\", experiment_id, \"final.txt\")\n",
        "\n",
        "# (a) Experiment configuration: convert experiment object to a JSON string.\n",
        "# Here we assume that the experiment values are simple objects; if not, you might need to\n",
        "# manually extract the serializable attributes.\n",
        "experiment_config_str = json.dumps({exp_name: vars(args) for exp_name, args in experiment.items()}, indent=4)\n",
        "\n",
        "# (b) Model configurations: for each experiment, load the .model_config file (assumed to be JSON).\n",
        "models_config = {}\n",
        "for exp_name, args in experiment.items():\n",
        "    model_config_path = args.model_config\n",
        "    if os.path.exists(model_config_path):\n",
        "        with open(model_config_path, \"r\") as f:\n",
        "            models_config[exp_name] = json.load(f)\n",
        "    else:\n",
        "        models_config[exp_name] = f\"Model configuration {model_config_path} not found.\"\n",
        "\n",
        "models_config_str = json.dumps(models_config, indent=4)\n",
        "\n",
        "# (c) Read the aggregated results (raw results) from results.json\n",
        "with open(results_save_path, \"r\") as f:\n",
        "    results_content = f.read()\n",
        "\n",
        "# (d) Read the summary from summary.txt\n",
        "with open(summary_save_path, \"r\") as f:\n",
        "    summary_content = f.read()\n",
        "\n",
        "# (e) Read the additional metrics from metrics.txt\n",
        "with open(metrics_save_path, \"r\") as f:\n",
        "    metrics_content = f.read()\n",
        "\n",
        "# Combine everything in the final file content according to the given template\n",
        "final_content = f\"\"\"Okay now let's move on to the next question X. Here is more information about the experiment for question X:\n",
        "\n",
        "Here is the configuration of the experiments of the question:\n",
        "{experiment_config_str}\n",
        "\n",
        "Here is the models configuration:\n",
        "{models_config_str}\n",
        "\n",
        "Here is the raw results of the training process:\n",
        "{results_content}\n",
        "\n",
        "Here is the summary of every model architecture:\n",
        "{summary_content}\n",
        "\"\"\"\n",
        "\n",
        "with open(final_save_path, \"w\") as final_file:\n",
        "    final_file.write(final_content)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ift",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
